<!DOCTYPE HTML>
<!--
	Strongly Typed by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Mariana Abreu Publications</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="no-sidebar is-preload">
		<div id="page-wrapper">


			<!-- Header -->
			<section id="header">
				<div class="container">

					<!-- Logo -->
						<h1 id="logo">Publications</h1>
						<p>My research experience started in 2018 at Fraunhofer AICOS, where I had the first contact with academic
                            applied research, and its challenges. Throughout this journey, I have been author and co-author of 9 papers in peer-reviewed journals, and 5 International Conferences.</p>

					<!-- Nav -->
						<nav id="nav">
							<ul>
								<li><a class="icon solid fa-home" href="index.html"><span>Homepage</span></a></li>
								
								<li><a class="icon solid fa-cog" href="no-sidebar.html"><span>About me</span></a></li>
								<li>
									<a href="#" class="icon fa-code"><span>Projects</span></a>
									<ul>
										<li><a href="project-1.html">Project 1</a></li>
										<li><a href="project-2.html">Project 2</a></li>
										<li><a href="project-3.html">Project 3</a></li>
										<li>
											<a href="#">Phasellus consequat</a>
											<ul>
												<li><a href="#">Magna phasellus</a></li>
												<li><a href="#">Etiam dolore nisl</a></li>
												<li><a href="#">Phasellus consequat</a></li>
											</ul>
										</li>
										<li><a href="#">Veroeros feugiat</a></li>
									</ul>
								</li>
								<li><a class="icon solid fa-newspaper" href="publications.html"><span>Publications</span></a></li>
							</ul>
						</nav>

				</div>
			</section>

			<!-- Main -->
				<section id="main">
                    
					<div class="container">
                        
						<div id="content">

									<!-- Excerpts -->
                                    <section>
                                        <ul class="divided">
                                            <li>

                                                <!-- Highlight -->
                                                    <article class="box highlight">
                                                        <header>
                                                            <h3><a href="https://www.frontiersin.org/journals/physiology/articles/10.3389/fphys.2023.1248899/full" target="_blank">PreEpiSeizures:
                                                                Description and Outcomes of Physiological Data Acquisition Using Wearable Devices during
                                                                Video-EEG Monitoring in People with Epilepsy</a></h3>
                                                                <p><strong>M. Abreu</strong>, A. S. Carmo, A. R. Peralta, F. Sá, H. P. da Silva, C. Bentes, A. Fred</p>
                                                        </header>
                                                        <a  class="image left"><img src="images/pic06.jpg" alt="" /></a>
                                                        
                                                        <p>The PreEpiSeizures project was created to better understand epilepsy and seizures through wearable technologies. The motivation was to capture physiological information related to epileptic seizures, besides Electroencephalography (EEG) during video-EEG monitorings. This work contributes with original wearable data and results relevant to epilepsy research, and discusses relevant challenges that impact wearable health monitoring.</p>
                                                        <ul class="icon fa-tag"> Health Monitoring, Wearable Devices, Data Acquisition, Signal Processing, Dataset Preparation </ul>
                                                        <ul class="actions">
                                                            <li><a href="https://www.frontiersin.org/journals/physiology/articles/10.3389/fphys.2023.1248899/full" target="_blank" class="button icon solid fa-file">Continue Reading</a></li>
                                                        </ul>
                                                    </article>

                                            </li>

                                            <li>

                                                <!-- Highlight -->
                                                <article class="box highlight">
                                                    <header>
                                                        <h3> <a href="https://doi.org/10.1111/epi.17677" target="_blank">A Novel Approach to Automatic Seizure Detection
                                                            Using Computer Vision and Independent Component Analysis</a> <br />  </h3>
                                                            <p>V. Garção, <strong>M. Abreu</strong>, A. Fred and H. P. da Silva</p>
                                                    </header>
                                                    <a  class="image left"><img src="images/pic06.jpg" alt="" /></a>
                                                    <p>The proposed approach is a video-based seizure-detection method based on optical flow, principal component analysis, independent component analysis, and machine learning classification. This method was tested on a set of 21 tonic–clonic seizure videos (5–30 min each, total of 4 h and 36 min of recordings) from 12 patients using leave-one-subject-out cross-validation.</p>
                                                    <ul class="icon fa-tag"> Computer Vision, Machine Learning, Seizure Detection </ul>
                                                    <ul class="actions">
                                                        <li><a href="https://doi.org/10.1111/epi.17677" target="_blank" class="button icon solid fa-file">Continue Reading</a></li>
                                                    </ul>
                                                </article>

                                            </li>
                                            <li>

                                                <!-- Highlight -->
                                                <article class="box highlight">
                                                    <header>
                                                        <h3> <a href="https://doi.org/10.3390/signals3010005" target="_blank">Mobile Applications for Epilepsy: Where Are We? Where Should We Go? A
                                                            Systematic Review</a> <br />  </h3>
                                                            <p><strong>M. Abreu</strong>, A. S. Carmo, A. Franco, S. Parreira, B. Vidal, M. Costa, A. R. Peralta, H. P. da Silva, C.
                                                                Bentes, A. Fred</p>
                                                    </header>
                                                    <a  class="image left"><img src="images/pic06.jpg" alt="" /></a>
                                                    <p>The development of mobile health for epilepsy has grown in the last years, bringing new applications (apps) to the market and improving already existing ones. In this systematic review, we analyse the scope of mobile apps for seizure detection and epilepsy self-management, with two research questions in mind: what are the characteristics of current solutions and do they meet users’ requirements? What should be considered when designing mobile health for epilepsy?</p>
                                                    <ul class="icon fa-tag"> Systematic Review, Self-management, Mobile Health </ul>
                                                    <ul class="actions">
                                                        <li><a href="https://doi.org/10.3390/signals3010005" target="_blank" class="button icon solid fa-file">Continue Reading</a></li>
                                                    </ul>
                                                </article>

                                            </li>
                                            <li>

                                                <!-- Highlight -->
                                                <article class="box highlight">
                                                    <header>
                                                        <h3> <a href="https://doi.org/10.3389/fninf.2022.837278" target="_blank">EpiBOX: An Automated Platform for Long-Term
                                                            Biosignal Collection</a> <br />  </h3>
                                                            <p>A. S. Carmo, <strong>M. Abreu</strong>, A. Fred, H. P. da Silva</p>
                                                    </header>
                                                    <a  class="image left"><img src="images/pic06.jpg" alt="" /></a>
                                                    <p>EpiBOX was developed as an open-source, standalone, and automated platform that enables the long-term acquisition of biosignals, passable to be operated by individuals with low technological proficiency. In particular, in this paper, we present an in-depth explanation of the framework, methods for the evaluation of its performance, and the corresponding findings regarding the perspective of the end-user.</p>
                                                    <ul class="icon fa-tag"> Data Acquisition Setup, Wearable Devices, Mobile Health, Continuous Monitoring </ul>
                                                    <ul class="actions">
                                                        <li><a href="https://doi.org/10.3389/fninf.2022.837278" target="_blank" class="button icon solid fa-file">Continue Reading</a></li>
                                                    </ul>
                                                </article>

                                            </li>
                                            <li>

                                                <!-- Highlight -->
                                                <article class="box highlight">
                                                    <header>
                                                        <h3> <a href="https://doi.org/10.3390/app12157404" target="_blank">Human-Assisted vs. Deep Learning Feature
                                                            Extraction: An Evaluation of ECG Features Extraction Methods for Arrhythmia Classification Using
                                                            Machine Learning</a> <br />  </h3>
                                                            <p>L. Montenegro, <strong>M. Abreu</strong>, A. Fred, J. M. Machado</p>
                                                    </header>
                                                    <a  class="image left"><img src="images/pic06.jpg" alt="" /></a>
                                                    <p>The success of arrhythmia classification tasks with Machine Learning (ML) algorithms is based on the handcrafting extraction of features from Electrocardiography (ECG) signals. However, feature extraction is a time-consuming trial-and-error approach. Deep Neural Network (DNN) algorithms bypass the process of handcrafting feature extraction since the algorithm extracts the features automatically in their hidden layers. </p>
                                                    <ul class="icon fa-tag">  Heart Arrhythmia, Convolutional Neural Network; Support Vector Machines; Handcrafted Features; Deep Features </ul>
                                                    <ul class="actions">
                                                        <li><a href="https://doi.org/10.3390/app12157404" target="_blank" class="button icon solid fa-file">Continue Reading</a></li>
                                                    </ul>
                                                </article>

                                            </li>
                                            <li>

                                                <!-- Highlight -->
                                                <article class="box highlight">
                                                    <header>
                                                        <h3> <a href="https://doi.org/10.1007/s00167-022-07082-4" target="_blank">Pre-Injury
                                                            Performance Is Most Important for Predicting the Level of Match Participation after Achilles
                                                            Tendon Ruptures in Elite Soccer Players: A Study Using a Machine Learning Classifier</a> <br />  </h3>
                                                            <p>P. Diniz, <strong>M. Abreu</strong>,  D. Lacerda, A. Martins, H. Pereira, F. Ferreira, G. Kerkhoffs, A. Fred</p>
                                                    </header>
                                                    <a  class="image left"><img src="images/pic06.jpg" alt="" /></a>
                                                    <p>Achilles tendon ruptures (ATR) are career-threatening injuries in elite soccer players due to the decreased sports performance they commonly inflict. This study presents an exploratory data analysis of match participation before and after ATRs and an evaluation of the performance of a machine learning (ML) model based on pre-injury features to predict whether a player will return to a previous level of match participation.</p>
                                                    <ul class="icon fa-tag"> Achilles tendon, Epidemiology, Football (soccer), General sports trauma, Machine learning, Statistics </ul>
                                                    <ul class="actions">
                                                        <li><a href="https://doi.org/10.1007/s00167-022-07082-4" target="_blank" class="button icon solid fa-file">Continue Reading</a></li>
                                                    </ul>
                                                </article>

                                            </li>
                                            <li>

                                                <!-- Highlight -->
                                                <article class="box highlight">
                                                    <header>
                                                        <h3> <a href="https://doi.org/10.1016/j.cmpb.2020.105675" target="_blank">Morphological Autoencoders for Apnea
                                                            Detection in Respiratory Gating Radiotherapy</a> <br />  </h3>
                                                            <p><strong>M. Abreu</strong>,  A. Fred, J. Valente, C. Wang, H. P. da Silva</p>
                                                    </header>
                                                    <a  class="image left"><img src="images/pic06.jpg" alt="" /></a>
                                                    <p>In this work, we devise a system based on autoencoders for classification of regular, apnea and unconstrained breathing patterns (i.e. multiclass).  Using autoencoders to learn respiratory gating training patterns allows a data-driven approach to feature extraction, by focusing only on the signal’s morphology. The proposed system is prone to be used in real-time and could potentially be transferred to other domains.</p>
                                                    <ul class="icon fa-tag"> Deep Learning, Machine Learning, Respiration, Apnea Detection </ul>
                                                    <ul class="actions">
                                                        <li><a href="https://doi.org/10.1016/j.cmpb.2020.105675" target="_blank" class="button icon solid fa-file">Continue Reading</a></li>
                                                    </ul>
                                                </article>

                                            </li>
                                            <li>

                                                <!-- Highlight -->
                                                <article class="box highlight">
                                                    <header>
                                                        <h3> <a href="https://doi.org/10.1016/j.softx.2020.100456" target="_blank">TSFEL: Time series feature extraction library</a> <br />  </h3>
                                                            <p>M. Barandas, D. Folgado, L. Fernandes, S. Santos, <strong>M. Abreu</strong>, P. Bota, H. Liu, T. Schultz, and H.
                                                                Gamboa</p>
                                                    </header>
                                                    <a  class="image left"><img src="images/pic06.jpg" alt="" /></a>
                                                    <p>We present in this paper a Python package entitled Time Series Feature Extraction Library (TSFEL), which computes over 60 different features extracted across temporal, statistical and spectral domains. TSFEL is designed to support the process of fast exploratory data analysis and feature extraction on time series with computational cost evaluation.</p>
                                                    <ul class="icon fa-tag"> Time series, Machine learning, Feature extraction, Python </ul>
                                                    <ul class="actions">
                                                        <li><a href="https://doi.org/10.1016/j.softx.2020.100456" target="_blank" class="button icon solid fa-file">Continue Reading</a></li>
                                                    </ul>
                                                </article>

                                            </li>

                                        </ul>
                                    
                                    </section>

					<div id="copyright" class="container">
						<ul class="links">
							<li>&copy; 2024, Mariana Abreu </li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
						</ul>
					</div>
				</section>

		</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>